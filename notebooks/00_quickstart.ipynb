{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç African Commodities Paradox - Quickstart Guide\n",
    "\n",
    "**Author:** Abraham Adegoke  \n",
    "**Date:** December 2025\n",
    "\n",
    "This notebook provides an interactive introduction to the African Commodities Paradox analysis tool.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What This Tool Does\n",
    "\n",
    "This project analyzes the relationship between **commodity dependence** and **economic volatility** in African countries.\n",
    "\n",
    "**Key Questions:**\n",
    "- Do resource-rich countries experience more volatile growth?\n",
    "- Which factors (commodity dependence, inflation, governance) amplify instability?\n",
    "- Can we predict GDP growth volatility using structural indicators?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup: Import Libraries and Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"üìÅ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù User Configuration\n",
    "\n",
    "Customize your analysis by modifying the parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìù USER CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "# Option 1: Choose specific countries (ISO3 codes)\n",
    "COUNTRIES = ['NGA', 'ZAF', 'KEN', 'GHA', 'EGY', 'DZA', 'AGO', 'ETH']\n",
    "\n",
    "# Option 2: Use a predefined subset (uncomment to use)\n",
    "# from yaml import safe_load\n",
    "# with open(project_root / 'configs/countries.yaml', 'r') as f:\n",
    "#     config = safe_load(f)\n",
    "# COUNTRIES = config['oil_exporters']  # or: mineral_dependent, agricultural, all_countries\n",
    "\n",
    "# Time period\n",
    "START_YEAR = 2000\n",
    "END_YEAR = 2023\n",
    "\n",
    "# Download settings\n",
    "DOWNLOAD_FRESH_DATA = False  # Set to True to download new data\n",
    "\n",
    "print(f\"üìä Analysis Configuration:\")\n",
    "print(f\"  Countries: {', '.join(COUNTRIES)}\")\n",
    "print(f\"  Period: {START_YEAR} - {END_YEAR}\")\n",
    "print(f\"  Download new data: {DOWNLOAD_FRESH_DATA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 1: Load or Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = project_root / 'data/raw/worldbank_wdi.csv'\n",
    "\n",
    "if DOWNLOAD_FRESH_DATA or not data_path.exists():\n",
    "    print(\"üì• Downloading data from World Bank...\")\n",
    "    print(\"(This may take 2-5 minutes depending on the number of countries)\\n\")\n",
    "    \n",
    "    from data_io.worldbank import fetch_wdi_data\n",
    "    \n",
    "    df_raw = fetch_wdi_data(\n",
    "        countries=COUNTRIES,\n",
    "        start_year=START_YEAR,\n",
    "        end_year=END_YEAR,\n",
    "        output_path=str(data_path)\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Downloaded {len(df_raw)} records\")\n",
    "else:\n",
    "    print(\"üìÇ Loading existing data...\")\n",
    "    df_raw = pd.read_csv(data_path)\n",
    "    print(f\"‚úÖ Loaded {len(df_raw)} records\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüìã Sample of raw data:\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 2: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"üìä Dataset Overview:\")\n",
    "print(f\"  Shape: {df_raw.shape}\")\n",
    "print(f\"  Countries: {df_raw['country'].nunique()}\")\n",
    "print(f\"  Years: {df_raw['year'].min()} - {df_raw['year'].max()}\")\n",
    "print(f\"  Total observations: {len(df_raw)}\")\n",
    "\n",
    "print(\"\\nüìà Countries in dataset:\")\n",
    "country_counts = df_raw.groupby('country_name')['year'].count().sort_values(ascending=False)\n",
    "print(country_counts)\n",
    "\n",
    "print(\"\\n‚ùå Missing values:\")\n",
    "missing = df_raw.isnull().sum()\n",
    "missing_pct = (missing / len(df_raw) * 100).round(1)\n",
    "missing_df = pd.DataFrame({'missing': missing, 'pct': missing_pct})\n",
    "print(missing_df[missing_df['missing'] > 0].sort_values('missing', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Commodity Dependence Index (CDI)\n",
    "if 'cdi_raw' in df_raw.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: CDI distribution\n",
    "    axes[0].hist(df_raw['cdi_raw'].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_xlabel('Commodity Dependence Index (%)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Distribution of Commodity Dependence (CDI)')\n",
    "    axes[0].axvline(df_raw['cdi_raw'].mean(), color='red', linestyle='--', \n",
    "                    label=f'Mean: {df_raw[\"cdi_raw\"].mean():.1f}%')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Plot 2: Average CDI by country\n",
    "    cdi_by_country = df_raw.groupby('country_name')['cdi_raw'].mean().sort_values(ascending=False).head(10)\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(cdi_by_country)))\n",
    "    axes[1].barh(range(len(cdi_by_country)), cdi_by_country.values, color=colors)\n",
    "    axes[1].set_yticks(range(len(cdi_by_country)))\n",
    "    axes[1].set_yticklabels(cdi_by_country.index)\n",
    "    axes[1].set_xlabel('Average CDI (%)')\n",
    "    axes[1].set_title('Top 10 Most Commodity-Dependent Countries')\n",
    "    axes[1].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüî• Most commodity-dependent countries:\")\n",
    "    print(cdi_by_country)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CDI column not found in data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 3: Feature Engineering\n",
    "\n",
    "Now we'll create the features needed for modeling:\n",
    "1. **CDI smoothing** (3-year moving average)\n",
    "2. **GDP growth volatility** (5-year rolling std)\n",
    "3. **Lagged features** (t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data\n",
    "df = df_raw.sort_values(['country', 'year']).copy()\n",
    "\n",
    "# 1. Smooth CDI with 3-year moving average\n",
    "print(\"‚öôÔ∏è  Applying 3-year moving average to CDI...\")\n",
    "if 'cdi_raw' in df.columns:\n",
    "    df['cdi_smooth'] = df.groupby('country')['cdi_raw'].transform(\n",
    "        lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è cdi_raw not found, skipping CDI smoothing\")\n",
    "\n",
    "# 2. Calculate 5-year rolling volatility of GDP growth\n",
    "print(\"üìä Calculating GDP growth volatility (5-year rolling std)...\")\n",
    "if 'gdp_growth' in df.columns:\n",
    "    df['gdp_volatility'] = df.groupby('country')['gdp_growth'].transform(\n",
    "        lambda x: x.rolling(window=5, min_periods=3).std()\n",
    "    )\n",
    "    # Log-transform volatility (as per proposal)\n",
    "    df['log_gdp_volatility'] = np.log(df['gdp_volatility'] + 0.01)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è gdp_growth not found, skipping volatility calculation\")\n",
    "\n",
    "# 3. Create lagged features (t-1)\n",
    "print(\"üîÑ Creating lagged features (t-1)...\")\n",
    "lag_features = ['cdi_smooth', 'inflation', 'trade_openness', 'investment']\n",
    "\n",
    "for feature in lag_features:\n",
    "    if feature in df.columns:\n",
    "        df[f'{feature}_lag1'] = df.groupby('country')[feature].shift(1)\n",
    "\n",
    "# Remove rows with NaN in target\n",
    "if 'log_gdp_volatility' in df.columns:\n",
    "    df_features = df.dropna(subset=['log_gdp_volatility'])\n",
    "else:\n",
    "    df_features = df.copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Feature engineering complete!\")\n",
    "print(f\"  Final dataset shape: {df_features.shape}\")\n",
    "print(f\"  Features created: {[col for col in df_features.columns if 'lag1' in col or 'smooth' in col or 'volatility' in col]}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüìã Sample with engineered features:\")\n",
    "display_cols = ['country_name', 'year', 'cdi_raw', 'cdi_smooth', 'gdp_growth', 'gdp_volatility', 'log_gdp_volatility']\n",
    "display_cols = [c for c in display_cols if c in df_features.columns]\n",
    "df_features[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relationship between CDI and volatility\n",
    "if 'cdi_smooth' in df_features.columns and 'log_gdp_volatility' in df_features.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Scatter plot\n",
    "    scatter_data = df_features.dropna(subset=['cdi_smooth', 'log_gdp_volatility'])\n",
    "    axes[0].scatter(scatter_data['cdi_smooth'], scatter_data['log_gdp_volatility'], alpha=0.5)\n",
    "    axes[0].set_xlabel('Commodity Dependence Index (smoothed)')\n",
    "    axes[0].set_ylabel('Log GDP Growth Volatility')\n",
    "    axes[0].set_title('CDI vs Economic Volatility')\n",
    "    \n",
    "    # Add trend line\n",
    "    if len(scatter_data) > 1:\n",
    "        z = np.polyfit(scatter_data['cdi_smooth'], scatter_data['log_gdp_volatility'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_line = np.linspace(scatter_data['cdi_smooth'].min(), scatter_data['cdi_smooth'].max(), 100)\n",
    "        axes[0].plot(x_line, p(x_line), \"r--\", alpha=0.8, label='Trend')\n",
    "        axes[0].legend()\n",
    "    \n",
    "    # Plot 2: Boxplot by CDI quartiles\n",
    "    df_features['cdi_quartile'] = pd.qcut(\n",
    "        df_features['cdi_smooth'].dropna(), \n",
    "        q=4, \n",
    "        labels=['Q1 (Low)', 'Q2', 'Q3', 'Q4 (High)']\n",
    "    )\n",
    "    \n",
    "    quartile_data = df_features.dropna(subset=['cdi_quartile', 'gdp_volatility'])\n",
    "    quartile_data.boxplot(column='gdp_volatility', by='cdi_quartile', ax=axes[1])\n",
    "    axes[1].set_xlabel('CDI Quartile')\n",
    "    axes[1].set_ylabel('GDP Growth Volatility')\n",
    "    axes[1].set_title('Economic Volatility by Commodity Dependence')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Volatility statistics by CDI quartile:\")\n",
    "    print(quartile_data.groupby('cdi_quartile')['gdp_volatility'].describe())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Required columns not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 4: Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to processed folder\n",
    "output_path = project_root / 'data/processed/features_ready.csv'\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Drop temporary columns\n",
    "if 'cdi_quartile' in df_features.columns:\n",
    "    df_features = df_features.drop(columns=['cdi_quartile'])\n",
    "\n",
    "df_features.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Processed data saved to: {output_path}\")\n",
    "print(f\"\\nüìä Final dataset summary:\")\n",
    "print(f\"  Shape: {df_features.shape}\")\n",
    "print(f\"  Countries: {df_features['country'].nunique()}\")\n",
    "print(f\"  Years: {df_features['year'].min()} - {df_features['year'].max()}\")\n",
    "print(f\"\\nüí° Next steps:\")\n",
    "print(f\"  1. Train models: python scripts/train_models.py\")\n",
    "print(f\"  2. Or continue exploring in this notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Quick Model Training (Optional)\n",
    "\n",
    "Let's do a quick model training to see initial results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "features = ['cdi_smooth_lag1', 'inflation_lag1', 'trade_openness_lag1', 'investment_lag1']\n",
    "target = 'log_gdp_volatility'\n",
    "\n",
    "# Check which features are available\n",
    "available_features = [f for f in features if f in df_features.columns]\n",
    "print(f\"Available features: {available_features}\")\n",
    "\n",
    "if target in df_features.columns and len(available_features) >= 2:\n",
    "    # Drop NaN\n",
    "    df_model = df_features[available_features + [target]].dropna()\n",
    "    print(f\"\\nModeling dataset: {len(df_model)} observations\")\n",
    "    \n",
    "    X = df_model[available_features]\n",
    "    y = df_model[target]\n",
    "    \n",
    "    # Train/test split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Train set: {len(X_train)} | Test set: {len(X_test)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough features or target variable for modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Ridge Regression\n",
    "if 'X_train' in dir():\n",
    "    from sklearn.linear_model import RidgeCV\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "    \n",
    "    # Train Ridge\n",
    "    ridge = RidgeCV(alphas=np.logspace(-2, 3, 50), cv=5)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nüìä Ridge Regression Results:\")\n",
    "    print(f\"  Best alpha: {ridge.alpha_:.4f}\")\n",
    "    print(f\"  R¬≤ Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    # Coefficients\n",
    "    print(\"\\nüìà Feature Coefficients:\")\n",
    "    coef_df = pd.DataFrame({\n",
    "        'feature': available_features,\n",
    "        'coefficient': ridge.coef_\n",
    "    }).sort_values('coefficient', key=abs, ascending=False)\n",
    "    print(coef_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
